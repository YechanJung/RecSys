{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Engagement Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch(\n",
    "    \"http://localhost:9200\",\n",
    "    basic_auth=(\"elastic\", \"password\"),\n",
    "    verify_certs=False,\n",
    "    ssl_show_warn=False\n",
    ")\n",
    "\n",
    "# Retrieve ABO data\n",
    "q = {\n",
    "    \"size\" : 1000,\n",
    "    \"query\": {\n",
    "        \"query_string\": {\n",
    "            \"query\": \"desk\",\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "result = es_client.search(index=\"product\", body=q)\n",
    "hits = result['hits']\n",
    "products = [hit['_source'] for hit in hits['hits']]\n",
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python -> Logstash -> Elasticsearch pipeline.\n",
    "\n",
    "import logging\n",
    "import logstash\n",
    "import random\n",
    "\n",
    "test_logger = logging.getLogger('Feedback')\n",
    "test_logger.setLevel(logging.DEBUG)\n",
    "if (test_logger.hasHandlers()):\n",
    "    test_logger.handlers.clear()\n",
    "test_logger.addHandler(logstash.TCPLogstashHandler('0.0.0.0', 5959 , version=1))\n",
    "\n",
    "sample = 100\n",
    "item_ids = df.limit(sample).select(\"item_id\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "for i in range(sample):\n",
    "    feedback = {\n",
    "        'user_id': str(i),\n",
    "        'item_id': item_ids[i],\n",
    "        'click': random.randrange(2),\n",
    "        'rating': random.randrange(6),\n",
    "    }\n",
    "\n",
    "    test_logger.info('INFO', extra=feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = {\n",
    "    \"size\": 100,\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    }\n",
    "}\n",
    "\n",
    "result = es_client.search(index=\"log\", body=q)\n",
    "hits = result['hits']\n",
    "feedback = [hit['_source'] for hit in hits['hits']]\n",
    "filter_keys = { 'item_id', 'user_id', 'click', 'rating' }\n",
    "feature_matrix = [dict((key, elem[key]) for key in elem.keys() & filter_keys) for elem in feedback]\n",
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)\n",
    "df = df.dropDuplicates()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"rating\"], outputCol=\"rating_vec\")\n",
    "scaler = MinMaxScaler(inputCol=\"rating_vec\", outputCol=\"scaled_rating\")\n",
    "pipeline = Pipeline(stages=[assembler, scaler])\n",
    "scaler_model = pipeline.fit(df)\n",
    "scaled_df = scaler_model.transform(df)\n",
    "scaled_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer_user = StringIndexer(inputCol='user_id', outputCol='user_index').setHandleInvalid(\"keep\")\n",
    "indexer_item = StringIndexer(inputCol='item_id', outputCol='item_index').setHandleInvalid(\"keep\")\n",
    "\n",
    "df_rec = indexer_user.fit(scaled_df).transform(scaled_df)\n",
    "df_rec = indexer_item.fit(df_rec).transform(df_rec)\n",
    "\n",
    "df_rec_final = df_rec.withColumn('item_index', df_rec['item_index'].cast('integer'))\\\n",
    "               .withColumn('user_index', df_rec['user_index'].cast('integer'))\n",
    "df_rec_final.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Alternating Least Square\n",
    "# https://dl.acm.org/doi/10.1109/MC.2009.263\n",
    "# computes user x rating and item x rating, given user x item matrix\n",
    "als = ALS(userCol='user_index', itemCol='item_index', ratingCol='rating',\n",
    "          coldStartStrategy='drop', nonnegative=True)\n",
    "\n",
    "model = als.fit(df_rec_final)\n",
    "# model.save(\"collaborative_filtering_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-10 recommendations for user_id 1\n",
    "recs = model.recommendForAllUsers(10).filter(col('user_index') == 1).select(\"recommendations\")\n",
    "recs = recs.rdd.flatMap(lambda x: x).collect()\n",
    "list(map(lambda x: x.asDict(), recs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metric\n",
    "\n",
    "# Offline metrics\n",
    "\n",
    "# Recall@k = first k relevent items / total relevant items\n",
    "# Precision@k = first k relevent items / k\n",
    "# MAP@k (Mean Average Precision) = (1/total users) * sum(average precision)\n",
    "# AP@k (Average Precision) = sum(precision of each position) / total relevant items\n",
    "\n",
    "# other offline metrics\n",
    "# Mean Absolute Error (MAE), Root Mean Squared Error (RMSE)\n",
    "# Normalized Discounted Cumulative Gain (NDCG)\n",
    "\n",
    "# Online metrics\n",
    "\n",
    "# A/B Testing\n",
    "# click-through rate (CTR), conversion rate (CR), and revenue per user (RPU)\n",
    "\n",
    "from pyspark.mllib.evaluation import RankingMetrics\n",
    "\n",
    "k = 5\n",
    "rdd = spark.sparkContext.parallelize([(['3','2','1','0'], ['3','2','0','1'])])\n",
    "metrics = RankingMetrics(rdd)\n",
    "\n",
    "print(metrics.meanAveragePrecisionAt(k))\n",
    "print(metrics.precisionAt(k))\n",
    "print(metrics.recallAt(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "  StructField('item_id', StringType(), True),\n",
    "  StructField('brand', StringType(), True),\n",
    "  StructField('item_name', StringType(), True),\n",
    "  StructField('item_keywords', StringType(), True),\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data=products, schema=schema)\n",
    "df = df.dropDuplicates()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature with item_keywords\n",
    "\n",
    "# tokenize user_query\n",
    "tokenizer = Tokenizer(inputCol=\"item_keywords\", outputCol=\"keywords\")\n",
    "tokenized_df = tokenizer.transform(df)\n",
    "tokenized_df.show()\n",
    "\n",
    "# vectorize using Word2Vec\n",
    "word2vec = Word2Vec(vectorSize=100, minCount=1, inputCol=\"keywords\", outputCol=\"keyword_vector\")\n",
    "word2vec_model = word2vec.fit(tokenized_df)\n",
    "word_vectors_df = word2vec_model.transform(tokenized_df)\n",
    "word_vectors_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_feature = word_vectors_df.select(['item_id', 'keyword_vector'])\n",
    "item_feature.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pinecone_api_key = 'e2c03eaa-fdf1-46ae-ac56-7e869b205322'\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "# Create Index\n",
    "index_name = \"item-feature\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=100,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "\n",
    "pc_client = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index item feature vector to Pinecone without Spark-Pinecone connector\n",
    "item_ids = item_feature.select(\"item_id\").rdd.flatMap(lambda x: x).collect()\n",
    "keyword_vector = item_feature.select(\"keyword_vector\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "vectors = []\n",
    "for _id, vec in zip(item_ids, keyword_vector):\n",
    "    vectors.append({\n",
    "        \"id\": _id,\n",
    "        \"values\": vec,\n",
    "    })\n",
    "\n",
    "pc_client.upsert(\n",
    "    vectors=vectors,\n",
    "    namespace=\"ns1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mock user history\n",
    "user_history = [\n",
    "    {'user_id': '1', 'query': ['computer desk', 'office desk']},\n",
    "]\n",
    "\n",
    "history_df = spark.createDataFrame(user_history)\n",
    "history_df.show()\n",
    "\n",
    "word2vec = Word2Vec(vectorSize=100, minCount=1, inputCol=\"query\", outputCol=\"query_vector\")\n",
    "word2vec_model = word2vec.fit(history_df)\n",
    "word_vectors_df = word2vec_model.transform(history_df)\n",
    "word_vectors_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feature = word_vectors_df.select(['user_id', 'query_vector'])\n",
    "user_feature.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "user_vector = user_feature.select(\"query_vector\").rdd.flatMap(lambda x: x).collect()[0].tolist()\n",
    "\n",
    "results = pc_client.query(\n",
    "    namespace=\"ns1\",\n",
    "    vector=user_vector,\n",
    "    top_k=3,\n",
    "    include_values=False,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "sorted_matches = sorted(results['matches'], key=lambda x: x['score'], reverse=True)\n",
    "print(sorted_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert item_index to item_id\n",
    "def get_item_id(rec_list):\n",
    "    item_ids = []\n",
    "    for item in rec_list:\n",
    "        _id = df_rec_final.filter(col('item_index') == item['item_index']).select('item_id').collect()[0]['item_id']\n",
    "        item_ids.append(_id)\n",
    "    return item_ids\n",
    "\n",
    "# weighted recommender\n",
    "def hybrid_recommendation(user_id, query_vector, explore=0.3, k=10):\n",
    "    explore_items = int(k*explore)\n",
    "    similar_items = k - explore_items\n",
    "    \n",
    "    # collaborative filtering\n",
    "    recs = model.recommendForAllUsers(explore_items).filter(col('user_index') == user_id).select(\"recommendations\")\n",
    "    recs = recs.rdd.flatMap(lambda x: x).collect()\n",
    "    rec_list = list(map(lambda x: x.asDict(), recs[0]))\n",
    "    item_ids = get_item_id(rec_list)\n",
    "    \n",
    "    # content-based filtering\n",
    "    results = pc_client.query(\n",
    "        namespace=\"ns1\",\n",
    "        vector=query_vector,\n",
    "        top_k=similar_items,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    \n",
    "    sorted_matches = sorted(results['matches'], key=lambda x: x['score'], reverse=True)\n",
    "    content_ids = list(map(lambda x: x['id'], sorted_matches))\n",
    "    final_rec = content_ids + item_ids\n",
    "    return final_rec\n",
    "\n",
    "hybrid_recommendation(1, user_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextual Bandit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class contextual_bandits():\n",
    "  def __init__(self, p):\n",
    "    self.p = p\n",
    "    # priors for the beta distribution\n",
    "    self.prior_alpha = 1\n",
    "    self.prior_beta = 1\n",
    "    # positive observations (i.e. clicks)\n",
    "    self.num_pos = 0\n",
    "    # negative observations (impressions - clicks)\n",
    "    self.num_neg = 0\n",
    "    self.bandit_id = \"\"\n",
    "\n",
    "  # thompson sampling\n",
    "  def sample(self):\n",
    "    return np.random.beta(self.prior_alpha, self.prior_beta)\n",
    "\n",
    "  def compute_posterior(self):\n",
    "    self.prior_alpha = self.prior_alpha + self.num_pos\n",
    "    self.prior_beta = self.prior_beta  + self.num_neg\n",
    "\n",
    "  def update_observations(self, clicks, impressions, curr_bandit_id):\n",
    "    self.num_pos = clicks\n",
    "    self.num_neg = impressions - clicks\n",
    "    self.bandit_id = curr_bandit_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runSimulation(trials=10000):\n",
    "    bandits = []\n",
    "    \n",
    "    bandit1 = contextual_bandits(.5)\n",
    "    bandit1.update_observations(10, 100, '1')\n",
    "    bandit1.compute_posterior()\n",
    "    bandits.append(bandit1)\n",
    "    \n",
    "    bandit2 = contextual_bandits(.5)\n",
    "    bandit2.update_observations(9, 90, '2')\n",
    "    bandit2.compute_posterior()\n",
    "    bandits.append(bandit2)\n",
    "    \n",
    "    bandit3 = contextual_bandits(.5)\n",
    "    bandit3.update_observations(12, 120, '3')\n",
    "    bandit3.compute_posterior()\n",
    "    bandits.append(bandit3)\n",
    "    \n",
    "    counts = {} \n",
    "    for i in range(trials):\n",
    "        # take a sample from each bandit\n",
    "        best_bandit = None\n",
    "        max_sample = -1\n",
    "        all_samples = [] \n",
    "        for b in bandits:\n",
    "          sample = b.sample()\n",
    "          all_samples.append(\"%f\" % sample)\n",
    "          if sample > max_sample:\n",
    "            max_sample = sample\n",
    "            best_bandit = b.bandit_id\n",
    "        counts[best_bandit] = counts.get(best_bandit, 0) + 1    \n",
    "        if i % 500 == 0:\n",
    "            print(\"current samples: %s\" % all_samples)\n",
    "            \n",
    "    # normalize the counts to get the traffic percenatge \n",
    "    normalized_counts = {}\n",
    "    for b in bandits:\n",
    "      normalized_counts[b.bandit_id] = float(counts.get(b.bandit_id, 0)) / trials \n",
    "    print(normalized_counts)\n",
    "\n",
    "runSimulation()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
